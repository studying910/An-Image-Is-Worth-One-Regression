{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA A100-PCIE-40GB, 40960 MiB, 17206 MiB\n",
      "NVIDIA A100-PCIE-40GB, 40960 MiB, 17206 MiB\n",
      "NVIDIA A100-PCIE-40GB, 40960 MiB, 17206 MiB\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute CLIP-space cosine-similarity distance\n",
    "import torch\n",
    "import os\n",
    "import clip\n",
    "import pathlib\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import warnings\n",
    "import json\n",
    "import sklearn.preprocessing\n",
    "from diffusers import StableDiffusionPipeline\n",
    "from transformers import CLIPFeatureExtractor, CLIPTextModel, CLIPTokenizer\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "from packaging import version\n",
    "from shutil import rmtree\n",
    "\n",
    "SEED = 1024\n",
    "DEVICE = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "pretrained_model_name_or_path = \"/root/autodl-tmp/stable_diffusion/stable-diffusion-v1-5\"\n",
    "learned_embeds_path = \"/root/autodl-tmp/textual_inversion/trained_embeddings/elephant/original/learned_embeds.bin\"\n",
    "original_image_dir = \"/root/autodl-tmp/textual_inversion/datasets/elephant\"\n",
    "# can also use downloaded embeddings \n",
    "all_embedding_path, embeds_suffix = os.path.split(learned_embeds_path)\n",
    "embeds_name, _ = os.path.splitext(embeds_suffix)\n",
    "dataset_path, _ = os.path.split(all_embedding_path)\n",
    "_, dataset_name = os.path.split(dataset_path)\n",
    "\n",
    "tokenizer = CLIPTokenizer.from_pretrained(\n",
    "    pretrained_model_name_or_path,\n",
    "    subfolder=\"tokenizer\",\n",
    ")\n",
    "text_encoder = CLIPTextModel.from_pretrained(\n",
    "    pretrained_model_name_or_path, subfolder=\"text_encoder\", torch_dtype=torch.float16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "placeholder token for dataset elephant: <elephant>\n"
     ]
    }
   ],
   "source": [
    "loaded_learned_embeds = torch.load(learned_embeds_path, map_location=\"cpu\")\n",
    "  \n",
    "# separate token and the embeds\n",
    "trained_token = list(loaded_learned_embeds.keys())[0]\n",
    "embeds = loaded_learned_embeds[trained_token]\n",
    "print(\"placeholder token for dataset {}:\".format(dataset_name), trained_token)\n",
    "\n",
    "# cast to dtype of text_encoder\n",
    "dtype = text_encoder.get_input_embeddings().weight.dtype\n",
    "embeds.to(dtype)\n",
    "\n",
    "# add the token in tokenizer\n",
    "num_added_tokens = tokenizer.add_tokens(trained_token)\n",
    "if num_added_tokens == 0:\n",
    "    raise ValueError(f\"The tokenizer already contains the token {trained_token}. \"\n",
    "                     \"Please pass a different `token` that is not already in the tokenizer.\")\n",
    "\n",
    "# resize the token embeddings\n",
    "text_encoder.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# get the id for the token and assign the embeds\n",
    "token_id = tokenizer.convert_tokens_to_ids(trained_token)\n",
    "text_encoder.get_input_embeddings().weight.data[token_id] = embeds\n",
    "\n",
    "pipe = StableDiffusionPipeline.from_pretrained(pretrained_model_name_or_path,\n",
    "                                               torch_dtype=torch.float16, \n",
    "                                               text_encoder=text_encoder, \n",
    "                                               tokenizer=tokenizer).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 1/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 2/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 3/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 4/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.58it/s]\n",
      "Potential NSFW content was detected in one or more images. A black image will be returned instead. Try again with a different prompt and/or seed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 5/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 6/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 7/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 8/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 9/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 10/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 11/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 12/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 13/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 14/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 15/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 16/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 17/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 18/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 19/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 20/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 21/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 22/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 23/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 24/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 25/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 26/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 27/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 28/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 29/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 30/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 31/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 32/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 33/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 34/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 35/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 36/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 37/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 38/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 39/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 40/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 41/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 42/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 43/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 44/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 45/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 46/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 47/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 48/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 49/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 50/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 51/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 52/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 53/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 54/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 55/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 56/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 57/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 58/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 59/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 60/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 61/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 62/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 18.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 63/64\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 17.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating images: 64/64\r"
     ]
    }
   ],
   "source": [
    "# Explicitly seperate \"object\" and \"style\"\n",
    "type_embedding_path = f\"{all_embedding_path}/type_of_concept.txt\"\n",
    "with open(type_embedding_path, \"r\") as f:\n",
    "    embedding_type = f.read()\n",
    "if embedding_type == \"object\":\n",
    "    prompt = \"A photo of {}\".format(trained_token) # Or \"A photo depicts <*>\"\n",
    "elif embedding_type == \"style\":\n",
    "    prompt = \"A painting in the style of {}\".format(trained_token) # Or \"A picture in the style of <*>\"\n",
    "else:\n",
    "    raise ValueError(\"Embedding type should be either 'object' or 'style'\")\n",
    "generator = None if SEED is None else torch.Generator(\n",
    "            device=DEVICE).manual_seed(SEED)\n",
    "N = 64  # number of random generated images\n",
    "clip_image_dir = os.path.join(all_embedding_path, \"clip_images\")\n",
    "os.makedirs(clip_image_dir, exist_ok=True)\n",
    "\n",
    "for n in range(N):\n",
    "    image_n = pipe(prompt, num_inference_steps=50, guidance_scale=7.5, \n",
    "                   generator=generator).images[0]\n",
    "    print(f\"Generating images: {n + 1}/{N}\", end=\"\\r\")\n",
    "    image_n_path = os.path.join(clip_image_dir, \"{}_{}.png\".format(prompt, n + 1))\n",
    "    image_n.save(image_n_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_images_path_list = [os.path.join(clip_image_dir, path) for path in os.listdir(clip_image_dir)\n",
    "                         if path.endswith(('.png', '.jpg', '.jpeg', '.tiff'))]\n",
    "original_images_path_list = [os.path.join(original_image_dir, path) for path in os.listdir(\n",
    "                        original_image_dir) if path.endswith(('.png', '.jpg', '.jpeg', '.tiff'))]\n",
    "num_original_images = len(original_images_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CLIPImageDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        # only 224x224 ViT-B/32 supported for now\n",
    "        self.preprocess = self._transform_test(224)\n",
    "\n",
    "    def _transform_test(self, n_px):\n",
    "        return Compose([\n",
    "            Resize(n_px, interpolation=Image.BICUBIC),\n",
    "            CenterCrop(n_px),\n",
    "            lambda image: image.convert(\"RGB\"),\n",
    "            ToTensor(),\n",
    "            Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
    "        ])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        c_data = self.data[idx]\n",
    "        image = Image.open(c_data)\n",
    "        image = self.preprocess(image)\n",
    "        return {'image': image}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_images(images, model, device, batch_size=64, num_workers=8):\n",
    "    data = torch.utils.data.DataLoader(\n",
    "        CLIPImageDataset(images),\n",
    "        batch_size=batch_size, num_workers=num_workers, shuffle=False)\n",
    "    all_image_features = []\n",
    "    with torch.no_grad():\n",
    "        for b in tqdm.tqdm(data):\n",
    "            b = b['image'].to(device)\n",
    "            b = b.to(torch.float16)\n",
    "            all_image_features.append(model.encode_image(b).cpu().numpy())\n",
    "    all_image_features = np.vstack(all_image_features)\n",
    "    return all_image_features\n",
    "\n",
    "def get_clip_score(model, clip_images, original_images, device, w=1.0):\n",
    "    if isinstance(clip_images, list):\n",
    "        # need to extract image features\n",
    "        clip_images = extract_all_images(clip_images, model, device)\n",
    "    if isinstance(original_images, list):\n",
    "        # need to extract image features\n",
    "        original_images = extract_all_images(original_images, model, device)\n",
    "    \n",
    "    # as of numpy 1.21, normalize doesn't work properly for float16\n",
    "    if version.parse(np.__version__) < version.parse('1.21'):\n",
    "        clip_images = sklearn.preprocessing.normalize(clip_images, axis=1)\n",
    "        original_images = sklearn.preprocessing.normalize(original_images, axis=1)\n",
    "    else:\n",
    "        warnings.warn(\n",
    "            'due to a numerical instability, new numpy normalization is slightly different than' \n",
    "            'paper results. To exactly replicate paper results, please use numpy version less' \n",
    "            'than 1.21, e.g., 1.20.3.')\n",
    "        clip_images = clip_images / np.sqrt(np.sum(clip_images ** 2, axis=1, keepdims=True))\n",
    "        original_images = original_images / np.sqrt(np.sum(original_images ** 2, axis=1, \n",
    "                                                           keepdims=True))\n",
    "    \n",
    "    per = w * np.clip(np.dot(clip_images, original_images.T), 0, None)\n",
    "    return np.mean(per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_125449/2880399981.py:9: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  Resize(n_px, interpolation=Image.BICUBIC),\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.38s/it]\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END!!! CLIP image2image score for learned_embeds is: 0.8515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/tmp/ipykernel_125449/2946529958.py:27: UserWarning: due to a numerical instability, new numpy normalization is slightly different thanpaper results. To exactly replicate paper results, please use numpy version lessthan 1.21, e.g., 1.20.3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clip_model, clip_transform = clip.load(\"ViT-B/32\", device=DEVICE, jit=False)\n",
    "clip_model.eval()\n",
    "\n",
    "clip_features = extract_all_images(clip_images_path_list, clip_model, DEVICE, batch_size=N, \n",
    "                                   num_workers=8)\n",
    "original_features = extract_all_images(original_images_path_list, clip_model, DEVICE, \n",
    "                                       batch_size=num_original_images, num_workers=8)\n",
    "\n",
    "# Compute pair-wise Clip-space cosine similarity\n",
    "final_score = get_clip_score(clip_model, clip_features, original_features, DEVICE)\n",
    "clip_score_dir = f\"{all_embedding_path}/i2i_score\"\n",
    "os.makedirs(clip_score_dir, exist_ok=True)\n",
    "clip_score_path = f\"{clip_score_dir}/{embeds_name}_i2i_score.txt\"\n",
    "with open(clip_score_path,\"w\") as f:\n",
    "    f.write(\"CLIP image2image score: {}\".format(final_score))\n",
    "print(\"END!!! CLIP image2image score for {} is: {}\".format(embeds_name, final_score))\n",
    "rmtree(clip_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dushian",
   "language": "python",
   "name": "dushian"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
